Starting training...

Epoch 1/3
Training Epoch 1: 100%|██████████████████████████| 526/526 [03:09<00:00,  2.78it/s, loss=0.3276, lr=1.95e-05]
Epoch 1 - Train Loss: 0.8563, Val Loss: 0.7417
/u/hli48/.local/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
Checkpoint saved to /projects/bfyv/hli48/sft_checkpoints/checkpoint-epoch-1

Epoch 2/3
Training Epoch 2: 100%|██████████████████████████| 526/526 [03:03<00:00,  2.86it/s, loss=0.8501, lr=8.56e-06]
Epoch 2 - Train Loss: 0.7159, Val Loss: 0.7403
Checkpoint saved to /projects/bfyv/hli48/sft_checkpoints/checkpoint-epoch-2

Epoch 3/3
Training Epoch 3: 100%|██████████████████████████| 526/526 [03:05<00:00,  2.83it/s, loss=0.8692, lr=5.17e-09]
Epoch 3 - Train Loss: 0.6684, Val Loss: 0.7397
Checkpoint saved to /projects/bfyv/hli48/sft_checkpoints/checkpoint-epoch-3
